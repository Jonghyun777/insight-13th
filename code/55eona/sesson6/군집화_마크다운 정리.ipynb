{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02163f47-1934-46ac-9b39-2bdf2cc985d7",
   "metadata": {},
   "source": [
    "# 1. 군집화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac964-fe3e-43c1-9fed-5a7e340c0a2c",
   "metadata": {},
   "source": [
    "## 1.1 머신러닝: 비지도 학습\n",
    "- 머신러닝: 컴퓨터가 스스로 학습할 수 있도록 돕는 알고리즘이나 기술 개발하는 분야\n",
    "- 비지도 학습\n",
    "  - 지도학습과 달리, 정답이 없는 데이터를 이용하는 머신러닝 방법 중 하나\n",
    "  - 모델의 성능을 정확히 측정 불가\n",
    "  - 데이터셋의 고유 패턴 식별 가능\n",
    "\n",
    "\n",
    "## 1.2 군집화란?\n",
    "### [군집화(clustering)]\n",
    "- 유사성을 기반으로 데이터들을 그룹화하는 방법\n",
    "- 군집(cluster): 유사한 데이터들의 집합/비슷한 특성을 가진 그룹\n",
    "- 종속변수 존재 X ==> 비지도 학습\n",
    "\n",
    "\n",
    "### [군집화 목표]\n",
    "- **응집도(cohension) 최대화**: 같은 군집의 데이터는 최대한 비슷하게!\n",
    "- **분리도(separaion) 최대화**: 서로 다른 군집은 최대한 분리되게!\n",
    "\n",
    "\n",
    "## 1.3 군집화 과정\n",
    "\n",
    "### [군집화 기본 과정]\n",
    "1. 피처 선택 또는 추출\n",
    "2. 군집화 알고리즘 선택\n",
    "3. 군집 유효성 검증\n",
    "4. 결과 해석\n",
    "\n",
    "### [주요 고려 사항]\n",
    "- 변수 유형 이해: 방법론을 결정하기 위해, 변수의 종류(연속형/명목형), 개수, 특징에 대한 이해 필요\n",
    "- 거리(distance) or 유사도(similarity) 정의와 측정: 군집화는 데이터 간의 유사도를 기반으로 이뤄지기 때문\n",
    "- 차원 축소: 유사한 변수들을 묶어서 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e6907d-6758-450c-be1b-a193b2cab652",
   "metadata": {},
   "source": [
    "# 2. 군집화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c04ec2-57b0-4c92-8f21-019a3545d519",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1 계층적 군집화\n",
    "\n",
    "### [계층적 군집화 (Hierarchical Clustering)]\n",
    "- 데이터의 유사성을 기반으로 덴드로그램을 형성하며 군집을 형성하는 방법\n",
    "- 종류\n",
    "  - 응집형 계층적 군집화 / 병합 클러스터링\n",
    "    - 덴드로그램이 **상향식**으로 형성\n",
    "    - 병합 클러스터링: 클러스터가 하나만 남을 때까지, 가장 가까운 클러스터를 병합\n",
    "  - 분리형 계층적 군집화 / 분할 클러스터링\n",
    "    - 덴드로그램이 **하향식**으로 형성\n",
    "    - 분할 클러스터링: 전체를 포함하는 하나의 클러스터에서 시작하여, 유사성이 낮은 데이터들을 더 작은 클러스터로 나눔\n",
    "\n",
    "### [응집형 계층적 군집화]\n",
    "- 1개의 데이터포인트만을 포함하는 N개의 군집에서 시작\n",
    "- 군집 간 거리 정의 방법에 따라 알고리즘이 달라짐\n",
    "- 소규모 데이터에 대해 유용\n",
    "- 군집 수 탐색 or  전반적인 구조 시각적으로 분석할 때 주로 활용\n",
    "\n",
    "### [6가지 거리 정의 방법]\n",
    "1. **Single linkage (단일/최단 연결법)**\n",
    "   - 군집 간의 거리 = 서로 다른 군집에서 가장 가까운 두 점 사이의 거리 \n",
    "   - 고립된 군집 찾는데 중점\n",
    "   - 이상치에 취약\n",
    "2. **Complete linkage (완전/최장 연결법)**\n",
    "   - 군집 간의 거리 = 서로 다른 군집에서 가장 먼 두 점 사이의 거리\n",
    "   - 군집들의 내부 응집성에 중점\n",
    "   - 이상치에 취약\n",
    "3. **Average linkage (평균 연결법)**\n",
    "   - 군집 간의 거리 = 모든 항목에 대한 거리의 평균\n",
    "   - 최단/최장 연결법보다 이상치에 둔감\n",
    "4. **Centroid Method (중심 연결법)**\n",
    "   - 군집 간의 거리 = 두 군집의 중심간의 거리\n",
    "   - 두 군집이 결합될 때, 새로운 군집의 평균은 가중 평균을 통해 계산\n",
    "   - 시간이 오래 걸림\n",
    "5. **Median (중앙 연결법)**\n",
    "   - 군집 간의 거리 = 군집 내 모든 샘플의 중앙값 간의 거리\n",
    "   - 극단값에 둔감\n",
    "   - 기하학적 구조 파악이 어려움\n",
    "6. **Ward's Procedure (Ward 연결)**\n",
    "    - 병합 후, 군집 내 SSE(오차 제곱 합)의 증가분 최소인 것을 선\n",
    "\n",
    "\n",
    "## 2.2 k-means\n",
    "### [k-means]\n",
    "- 데이터를 k개의 그룹으로 나눈 뒤, 각 그룹의 중심점(centroid)과 거리가 가장 가까운 데이터끼리 묶는 방법\n",
    "  \n",
    "### [k-means 알고리즘 주요 단계]\n",
    "1. 무작위로 k개의 중심(centroid)을 초기 군집 중심으로 선택\n",
    "2. 각 표본을 가장 가까운 중심점에 할당\n",
    "   - $x(i)$: i번째 데이터포인트\n",
    "   - $u(j)$: j번째 군집 중심(centroid)\n",
    "   - **제곱오차합(SSE)**를 통해 $x(i)$와 $u(j)$의 거리를 최소가 되는 $j$번째 군집을 찾아냄\n",
    "4. 각 군집에 할당된 표본들의 데이터 평균을 계산하여 중심점 이동시킴\n",
    "5. 군집 할당이 변하지 X or 지정한 허용 오차 도달 or 최대 반복 횟수(`max_iter`) 도달할 때까지 2,3번 반복\n",
    "\n",
    "### [k-means 장단점]\n",
    "- 장점\n",
    "  - 직관적이 구현이 쉬움\n",
    "  - 대용량 데이터도 적용 가능\n",
    "- 단점\n",
    "  - 초기 중심점(centroid)값에 민감\n",
    "  - k 결정이 어려움\n",
    "  - 아웃라이어에 민감\n",
    "  - 기하학적인 모양의 군집은 파악 어려움\n",
    "\n",
    "### [k-means++ 알고리즘]\n",
    "- 랜덤하게 할당된 초기 중심점에 따라 군집화 품질, 알고리즘 성능 달라짐\n",
    "- k-means++ 알고리즘 통해, 초기 중심점들을 서로 멀리 떨어진 곳에 위치시킴 ==> k-means 보다 일관되고 좋은 결과 도출 가능\n",
    "\n",
    "#### k-means++ 알고리즘의 초기화 과정\n",
    "1. 선택한 k개의 중심점 저장할 빈 집합 $\n",
    "\\mathbf{M}$을 초기\n",
    "2. 입력 샘플에서 첫번째 중심점$\n",
    "\\mathbf{\\mu}^{(i)}$을 랜덤하게 선택하고 $\\mathbf{M}$에 할\n",
    "3. $\\mathbf{M}$에 없는 각 샘플$\\mathbf{x^{(i)}}$에 대해 $\\mathbf{M}$에 있는 중심점까지의 최소제곱거리\r",
    "$\n",
    "d(\\mathbf{x}^{(i)}, \\mathbf{M})^2$을 찾음.\n",
    "4. 가중치가 적용된 확률분포를 사용해 다음 중심점을 랜덤하게 선\n",
    "5.  k개의 중심점을 선택할 때까지 3,4번 반복\n",
    "6.  기본 k-means 알고리즘 수행당화\n",
    "\n",
    "### [엘보우 방법]\n",
    "- 최적의 군집 개수 k를 추정하는 방법\n",
    "- 클래스 내 SSE를 통해 계산\n",
    "- 왜곡이 빠르게 감소하는 지점이 최적의 k값!\n",
    "\n",
    "\n",
    "## 2.3 DBSCAN\n",
    "\n",
    "### [DBSCAN]\n",
    "- 밀도가 높은 지역의 데이터를 하나의 군집으로 묶고, 밀도 기준을 만족하지 못하는 데이터는 군집에 포함하지 않는 군집화 알고리즘\n",
    "### [DBSCAN 알고리즘 주요 단계]\n",
    "1. 각 샘플을 핵심 샘플, 경계 샘플, 잡음 샘플 중 하나에 할당\n",
    "   - 핵심샘플(core point): 특정 반경 $\\epsilon$ 안에 있는 이웃 샘플이 지정된 개수(MinPts) 이상일 때\n",
    "   - 경계 샘플(border point): 핵심샘플이 아니지만 다른 핵심 샘플의 반경 안에 있을 때\n",
    "   - 잡음 샘플(noise point): 둘 중 어디에도 포함 안될 때\n",
    "2. 개별 핵심 샘플 또는 핵심 샘플의 그룹을 군집으로 구성\n",
    "3. 경계 샘플을 해당 핵심 샘플의 군집에 할당\n",
    "\n",
    "#### 하이퍼파라미터\n",
    "- `eps`: 데이터 포인트 사이의 최대 거리\n",
    "- `min_samples`: 포인트가 군집이 되기 위해 필요한 `eps`거리 내 최소 포인트 개수\n",
    "  - `min_samples` 증가할수록, 군집 수 감소\n",
    "\n",
    "### [DBSCAN 장단점]\n",
    "- 장점\n",
    "  - 기하학적 분포의 데이터 처리 가\n",
    "  - 이상치에 둔감\n",
    "  - 잡음 샘플 구분 가능\n",
    "\n",
    "- 단점\n",
    "  - `eps`, `min_samples` 영향을 많이 받음\n",
    "  - `epsilon` 조절 위해 데이터셋에 대한 도메인 지식 필요\n",
    "  - 속도가 느림\n",
    "  - 다른 밀도 분포의 데이터 군집 분석 어려움\n",
    "  - 차원의 저주 벗어나지 X\n",
    "\n",
    "## 2.4 Gaussian Mixture Model (GMM)\n",
    "### [Gaussian Mixture Model (GMM)]\n",
    "- 각 군집을 확률분포로 간주하고 전체 데이터분포를 여러 확률분포의 혼합으로 간주하고, 각 분포를 군집으로 인식하는 군집화 방식\n",
    "\n",
    "### [GMM 가정]\n",
    "- 데이터포인트들은 특정 가우시안 확률분포에 의해 생성\n",
    "- 전체 데이터셋에는 여러개의 가우시안 분포가 섞여 있고, 개별데이터에는 우도(가능도)에 따라 K개의 가우시안 분포 중 한가지에 속함\n",
    "\n",
    "### [GMM 진행과정]\n",
    "1. 전체 데이터셋의 분포 확인\n",
    "2. 전체 데이터 셋이 서로 다른 정규분포 형태의 확률 분포 곡선으로 구성되어 있다고 가정\n",
    "3. 여러개의 정규분포 곡선 추출, 개별 데이터가 어느 정규분포에 속하는지 결정\n",
    "   - 각 정규분포를 하나의 군집으로 판단\n",
    "\n",
    "### [모델의 파라미터 추정정]\n",
    "- 기댓값-최대화(Expectation-Maximization, EM)알고리즘 통해 파라미터 추정\n",
    "\n",
    "$\\text{parameter}\\theta = (u, \\Sigma, \\pi) $<BR>\n",
    "$\\text{hyper parameter}K(\\text{분포 개수})$\n",
    "\n",
    "\n",
    "### [GMM 장단점]\n",
    "- 장점\n",
    "  - 다양한 데이터 셋에 적용 가능\n",
    "\n",
    "- 단점\n",
    "  - 속도가 느림\n",
    "  - 가정한 분포에 맞지 않는 경우, 성능 저하 우려"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68831e9c-d571-43cf-8182-58aa5b8e1d3d",
   "metadata": {},
   "source": [
    "# 3. 군집화의 평가방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed999c49-c79c-4e9b-a30f-c54db9c0da4f",
   "metadata": {},
   "source": [
    "### [군집화의 평가방법]\n",
    "- 내부 평가\n",
    "  - 정답 라벨이 없는 경우\n",
    "  - 군집 내부의 응집도와 군집 간의 분리도를 통해 군집 품질을 평가\n",
    "  - 실루엣 계수\n",
    "- 외부 평가\n",
    "  - 정답 라벨이 없는 경우\n",
    "  - 실제 라벨과 군집화 결과를 비교\n",
    "  - ARI\n",
    "\n",
    "## 3.1 실루엣 계수\n",
    "\n",
    "### [실루엣 계수 (silhouette coefficient)]\n",
    "- 군집 내 샘플들이 얼마나 모여있는지 측정\n",
    "- -1과 1 사이의 값\n",
    "- `평균 실루엣 계수>=0.7` ==> 좋은 군집화 결과\n",
    "\n",
    "### [실루엣 계수 계산 과정]\n",
    "$$s^{(i)} = \\frac{b^{(i)} - a^{(i)}}{\\max \\{b^{(i)}, a^{(i)} \\}} $$}\n",
    "- $a^{(i)}$: 군집 응집력/샘플과 동일한 군집 내 다른 포인트 사이의 거리의 평균\r",
    "- $b^{(i)}$: 군집 분리도/샘플과 가장 가까운 군집의 모든 샘플 간 평균 거리\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3.2 Dunn Index\n",
    "### [Dunn Index]\n",
    "$$\\text{Dunnn Index} = \\frac{\\min\\limits_{i \\ne j} \\; d(C_i, C_j)}{\\max\\limits_{1 \\le k \\le K} \\; \\delta(C_k)}$$\n",
    "- 군집 간 최소거리($d(C_i, C_j)$)와 군집 내 최대 거리($\\delta(C_k)$)의 비율로 군집화의 품질 평가하는 지표\n",
    "- Dunn Index 값 클수록, 좋은 군집화 결과\n",
    "\n",
    "### [Dunn Index 한계]\n",
    "- 군집수 많아질 수록, 계산 비용 증가\n",
    "- 이상치에 민감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca9499-604d-435f-bea6-2795e6ab93c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
